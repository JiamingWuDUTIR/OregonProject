{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib as tfc\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1' #使用 GPU \n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "def use_gpu_polite(using_rate=0.6):\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = using_rate\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探讨单双向RNN和单双向LSTM的输出问题  \n",
    "RNN比较简单，status只有一个，双向也就简单concat一下就好了。  \n",
    "LSTM相对复杂，因为status包含c和h，h就是ouput的最后一步。  \n",
    "**由于双向的结构是外层正反向列表，内层c和h列表。所以要拼接比较麻烦。**  \n",
    "**千万注意，lstm的status的构成是先c，后h**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dutir923/wujiaming/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:430: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n",
      "WARNING:tensorflow:From /home/dutir923/wujiaming/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n",
      "\n",
      "11111111.输入的x\n",
      "[[[0.02503985 0.70159322]\n",
      "  [0.70557438 0.78248669]\n",
      "  [0.62221984 0.41850192]]\n",
      "\n",
      " [[0.68420447 0.98017391]\n",
      "  [0.88879729 0.51480725]\n",
      "  [0.48024142 0.20397805]]]\n",
      "\n",
      "22222222.双向rnn的output和status，比较两个方向和拼接后的结果，status是正加反：\n",
      "[[[-0.3485087   0.4817568   0.1782444   0.5397934   0.03973075]\n",
      "  [-0.00605379  0.2663573   0.11327919 -0.02078193 -0.09425943]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.23104002  0.62741125 -0.10117388  0.2911049  -0.29898652]\n",
      "  [ 0.03270912 -0.03880924 -0.1780076  -0.36942184 -0.30528158]\n",
      "  [ 0.0140127   0.09617876 -0.32880777 -0.26975223 -0.10410229]]]\n",
      "[[-0.00605379  0.2663573   0.11327919  0.5397934   0.03973075]\n",
      " [ 0.0140127   0.09617876 -0.32880777  0.2911049  -0.29898652]]\n",
      "(array([[-0.00605379,  0.2663573 ,  0.11327919],\n",
      "       [ 0.0140127 ,  0.09617876, -0.32880777]], dtype=float32), array([[ 0.5397934 ,  0.03973075],\n",
      "       [ 0.2911049 , -0.29898652]], dtype=float32))\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "33333333.单向LSTM的output和status中的h，c\n",
      "[[[-0.00466959 -0.07455504 -0.07391993]\n",
      "  [ 0.06436605 -0.15295385 -0.08889129]\n",
      "  [ 0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.05791391 -0.12517159 -0.05365822]\n",
      "  [ 0.12368973 -0.18150619 -0.04325755]\n",
      "  [ 0.16021106 -0.21145372 -0.04914615]]]\n",
      "[[ 0.06436605 -0.15295385 -0.08889129]\n",
      " [ 0.16021106 -0.21145372 -0.04914615]]\n",
      "[[ 0.17396517 -0.42198047 -0.17545347]\n",
      " [ 0.37225437 -0.5659299  -0.10110136]]\n",
      "\n",
      "44444444.双向LSTM的output，正确的h，巧妙的h\n",
      "[[[-0.07455006  0.05853856 -0.0601063   0.09695473  0.22367069]\n",
      "  [-0.14947568  0.05777396 -0.09049162  0.11525057  0.16125813]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.09934106  0.03705737 -0.05979967  0.27473018  0.3512699 ]\n",
      "  [-0.13905644  0.00156098 -0.08134162  0.18788427  0.2051627 ]\n",
      "  [-0.12837487 -0.0133464  -0.09395183  0.0652554   0.08031906]]]\n",
      "[[-0.14947568  0.05777396 -0.09049162  0.09695473  0.22367069]\n",
      " [-0.12837487 -0.0133464  -0.09395183  0.27473018  0.3512699 ]]\n",
      "[[ 0.          0.          0.          0.          0.        ]\n",
      " [-0.12837487 -0.0133464  -0.09395183  0.0652554   0.08031906]]\n"
     ]
    }
   ],
   "source": [
    "x_input = tf.placeholder(tf.float32, [None, 3, 2])\n",
    "input_len = tf.placeholder(tf.int32, [None])\n",
    "f_size, b_size = 3, 2\n",
    "\n",
    "# 单向rnn\n",
    "rnn_o, rnn_s = tf.nn.dynamic_rnn(tfc.rnn.BasicRNNCell(f_size), x_input, dtype=tf.float32,\n",
    "                                sequence_length=input_len)\n",
    "# 双向rnn，所以返回的output和status都是tuple,  \n",
    "# outputs shaope: [batch_size * time_step * dim_f, ... * dim_b] 两个方向可以不同维度\n",
    "rnn_b_o, rnn_b_s = tf.nn.bidirectional_dynamic_rnn(tfc.rnn.BasicRNNCell(f_size), tfc.rnn.BasicRNNCell(b_size),\n",
    "                                                   x_input, dtype=tf.float32, sequence_length=input_len)\n",
    "rnn_b_o_c = tf.concat(rnn_b_o, axis=-1)\n",
    "rnn_b_s_c = tf.concat(rnn_b_s, axis=-1)\n",
    "\n",
    "\n",
    "# 单向lstm, status 分为 c 和 h\n",
    "lstm_o, (lstm_c, lstm_h) = tf.nn.dynamic_rnn(tfc.rnn.LSTMCell(f_size), x_input,\n",
    "                                             dtype=tf.float32, sequence_length=input_len)\n",
    "# 双向lstm\n",
    "lstm_b_o, (lstm_f_s, lstm_b_s) = tf.nn.bidirectional_dynamic_rnn(tfc.rnn.LSTMCell(f_size), tfc.rnn.LSTMCell(b_size),\n",
    "                                                   x_input, dtype=tf.float32, sequence_length=input_len)\n",
    "lstm_b_o_c = tf.concat(lstm_b_o, axis=-1)\n",
    "\n",
    "lstm_f_c, lstm_f_h = lstm_f_s  # 前向的c和h\n",
    "lstm_b_c, lstm_b_h = lstm_b_s  # 后向的c和h\n",
    "lstm_h_concate = tf.concat([lstm_f_h, lstm_b_h], axis=-1)  # 拼接正反的h\n",
    "lstm_b_o_c_0 = tf.reverse(lstm_b_o_c, axis=[1])[:, 0, :]  # 先按照time step翻转，然后取第一步\n",
    "\n",
    "\n",
    "# 实际运行环节\n",
    "x_in = np.random.random([2, 3, 2])\n",
    "len_in = np.array([2, 3])\n",
    "config = use_gpu_polite()\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    rbs, rboc, rbsc = sess.run([rnn_b_s, rnn_b_o_c, rnn_b_s_c], {x_input: x_in, input_len: len_in})\n",
    "    lo, lc, lh = sess.run([lstm_o, lstm_c, lstm_h], {x_input: x_in, input_len: len_in})\n",
    "    lboc, lbhc = sess.run([lstm_b_o_c, lstm_h_concate], {x_input: x_in, input_len: len_in})\n",
    "    lboc0 = sess.run(lstm_b_o_c_0, {x_input: x_in, input_len: len_in})\n",
    "    print('\\n11111111.输入的x')\n",
    "    print(x_in)\n",
    "    print('\\n22222222.双向rnn的output和status，比较两个方向和拼接后的结果，status是正加反：')\n",
    "    print(rboc)\n",
    "    print(rbsc)\n",
    "    print(rbs)\n",
    "    print('-' * 100)\n",
    "    print('\\n33333333.单向LSTM的output和status中的h，c')\n",
    "    print(lo)\n",
    "    print(lh)\n",
    "    print(lc)\n",
    "    print('\\n44444444.双向LSTM的output，正确的h，巧妙的h')\n",
    "    print(lboc)\n",
    "    print(lbhc)\n",
    "    print(lboc0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 使用text-lstm的时候，我们一般有两个思路：  \n",
    "### 第一个是使用每个步长的输出，也即output  \n",
    "### 第二个就是只取最终输出  \n",
    "1. 单向很简单，也就是status中的h  \n",
    "2. 双向比较复杂，需要不断解开tuple，最后拼接，变量“lstm_h_concate”就是这么做到  \n",
    "3. 另一种方法比较简单，首先把output按照time step翻转，然后取第一步，变量“lstm_b_o_c_0”就是这么做的  \n",
    "**但是，这是不对的，当seq len不是全长，就会得到0。而且它得到的是正向结尾+反向开头**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
